{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis with the Discrete Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_png(array, output_path):\n",
    "    if array.dtype != np.uint8:\n",
    "        array = (array * 255).astype(np.uint8)\n",
    "    img = Image.fromarray(array)\n",
    "    img.save(output_path)\n",
    "\n",
    "\n",
    "matrix = np.zeros((8, 8))\n",
    "matrix[1,0] = 1\n",
    "# save_as_png(matrix, 'img.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_matrix(matrix):\n",
    "    N, M = matrix.shape\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            val = matrix[i,j]\n",
    "            if isinstance(val, complex):\n",
    "                print(f\"{val.real:.4f}+{val.imag:.4f}j\", end=\" \")\n",
    "            else:\n",
    "                print(f\"{val:.4f}\", end=\" \")\n",
    "        print()\n",
    "\n",
    "def display(a: np.ndarray, title=\"\") -> None:\n",
    "    plt.title(title)\n",
    "    plt.imshow(a, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def display_in_grid(matrix_of_images_2d, titles=None):\n",
    "    rows = len(matrix_of_images_2d)\n",
    "    cols = len(matrix_of_images_2d[0])\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if rows == 1:\n",
    "                ax = axes[j]\n",
    "            elif cols == 1:\n",
    "                ax = axes[i]\n",
    "            else:\n",
    "                ax = axes[i,j]\n",
    "            \n",
    "            ax.imshow(matrix_of_images_2d[i][j], cmap='gray')\n",
    "\n",
    "            ax.axis('off')\n",
    "            if titles:\n",
    "                ax.set_title(titles[i][j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretized Sine and Cosine in 2D\n",
    "\n",
    "In 2D the sine and cosine waves can be represented by the functions:\n",
    "\n",
    "$s_{u,v}[n,m] = A \\sin(2\\pi(\\frac{un}{N} + \\frac{vm}{M}))$ \n",
    "\n",
    "$c_{u,v}[n,m] = A \\cos(2\\pi(\\frac{un}{N} + \\frac{vm}{M}))$\n",
    " \n",
    "- $u$, $v$ modulate the frequency in the rows and columns\n",
    "- $A$ is the amplitude of the wave\n",
    "- $N$, $M$ represent the number of rows, columns in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_2d(N,M, u=1, v=1):\n",
    "    n = np.arange(N)[:, np.newaxis]  \n",
    "    m = np.arange(M)[np.newaxis, :] \n",
    "    s = np.sin(2 * np.pi * (u*n/N + v*m/M))\n",
    "    return s\n",
    "\n",
    "def cos_2d(N,M, u=1, v=1):\n",
    "    n = np.arange(N)[:, np.newaxis]  \n",
    "    m = np.arange(M)[np.newaxis, :] \n",
    "    c = np.cos(2*np.pi*(u*n/N + v*m/M))\n",
    "    return c\n",
    "\n",
    "display_in_grid([[sin_2d(1000,1000), cos_2d(1000,1000)]], [[\"Sin (1000x1000)\", \"Cos (1000x1000)\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize the sine wave in 3D, with the Z axis representing the amplitude (pixel intensity). The blue and red lines show cross-sections of the wave at x=0 and y=0 respectively, demonstrating how 2D sine waves combine to create the full surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "x = np.linspace(0, 1, N)\n",
    "y = np.linspace(0, 1, N)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = sin_2d(N, N)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='gray')\n",
    "fig.colorbar(surf)\n",
    "\n",
    "x_line = np.linspace(0, 1, N)\n",
    "y_line = np.linspace(0, 1, N)\n",
    "xz_line = np.sin(2*np.pi*x_line)\n",
    "yz_line = np.sin(2*np.pi*y_line)\n",
    "ax.plot(x_line, np.zeros_like(x_line), xz_line, color='blue', linewidth=3)\n",
    "ax.plot(np.zeros_like(y_line), y_line, yz_line, color='red', linewidth=3)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "ax.set_title('2D Sine Wave')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also vary the size of the image to see how visually the wave stretches/contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = range(25,100,25)\n",
    "image_grid = [[sin_2d(x,y) for y in interval] for x in interval]\n",
    "plot_titles = [[f\"sin(N={x},M={y})\" for y in interval] for x in interval]\n",
    "display_in_grid(image_grid, plot_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can modulate the frequencies of u, v to see how the wave rotates. We do this with linear spacing and logarithmic spacing so you can observe how these values impact the function locally and towards infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = np.linspace(-5, 5, num=5)\n",
    "image_grid = [[sin_2d(100,100, u,v) for u in interval] for v in interval]\n",
    "plot_titles = [[f\"u,v = ({u:.3f},{v:.3f})\" for u in interval] for v in interval]\n",
    "display_in_grid(image_grid, plot_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = np.logspace(-2, 3, base=10, num=10)\n",
    "image_grid = [[sin_2d(100,100, u,v) for u in interval] for v in interval]\n",
    "plot_titles = [[f\"u,v = ({u:.3f},{v:.3f})\" for u in interval] for v in interval]\n",
    "display_in_grid(image_grid, plot_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Fourier Transform in 2D\n",
    "\n",
    "Let’s begin with Euler’s identity, which connects trigonometric functions with complex exponentials:\n",
    "$$ e^{j\\theta} = \\cos(\\theta) + j\\sin(\\theta) $$\n",
    "\n",
    "Given an image $l[n,m]$, of size N×M, we can define the basis function:\n",
    " \n",
    "$$ \n",
    "e_{u,v}[n,m] = e^{2\\pi j(\\frac{un}{N}+\\frac{vm}{M})}\n",
    "$$\n",
    "This represents a 2D complex sinusoid at spatial frequency $(u,v)$. Any discrete image can be decomposed as a linear combination of these. In this formula, the $2\\pi$ scales each of our axis to the unit circle and the $(\\frac{un}{N}+\\frac{vm}{M})$ tells us how far into each dimension of the discrete image we are. \n",
    "\n",
    "We will not prove that the basis functions are orthogonal, but it is possible via the following:\n",
    "\n",
    "$$\\langle e_{u,v}, e_{u',v'} \\rangle = 0 \\quad \\forall (u\\neq u'),(v\\neq v') $$\n",
    "\n",
    "\n",
    "### Discrete Fourier Transform: \n",
    "\n",
    "$$L[u,v] = \\sum_{n=0}^{N-1} \\sum_{m=0}^{M-1} l[n,m]e^{-2\\pi j (\\frac{un}{N}+\\frac{vm}{M})}$$\n",
    "\n",
    "Each coefficient in $L[u,v]$ represents the contribution of a 2D sinusoidal pattern at spatial frequency $(u,v)$. Each term is computed by the inner product between the image and the basis function $e_{u,v}[n,m]$, which intuitively tells us how much of each particular frequency exists in the image.\n",
    "\n",
    "The DFT decomposes the image into a weighted sum of these frequency components, separating structure (phase) from texture/detail (magnitude).\n",
    "\n",
    "- $∣L[u,v]∣$ is the magnitude spectrum: how much of the frequency exists\n",
    "- $\\arg{(L[u,v])}$ is the phase spectrum: this is the spatial offset of the sinusoid \n",
    "\n",
    "### Inverse:\n",
    "\n",
    "$$l[n,m] = \\frac{1}{NM} \\sum_{u=0}^{N-1} \\sum_{v=0}^{M-1} L[u,v]e^{+2\\pi j (\\frac{un}{N}+\\frac{vm}{M})}$$\n",
    "\n",
    "The inverse DFT reconstructs the image as a weighted sum of complex sinusoids.\n",
    "Each term contributes a wave pattern whose amplitude is $∣L[u,v]∣$ and shift is determined by $\\arg{(L[u,v])}$.\n",
    "\n",
    "### Computing the DFT\n",
    "\n",
    "Below I will lay out the discrete fourier transform (and it's inverse) manually. Computing the DFT in this way is extremely computationally inefficient, and there are much faster ways to compute the discrete fourier transform. In future examples I will use numpy's fft2() functions to perform this operation in $O(N^2log(N))$ time complexity instead of $O(N^4)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fourier_tfm_slow(image: np.ndarray) -> np.ndarray:\n",
    "    N,M = image.shape\n",
    "    output = np.zeros((N,M), dtype=complex)\n",
    "    for u in range(N):\n",
    "        for v in range(M):\n",
    "            for n in range(N):\n",
    "                for m in range(M):\n",
    "                    output[u,v] += image[n,m] * np.exp(-2j*np.pi*((u*n/N)+(v*m/M)))\n",
    "    return output\n",
    "\n",
    "def compute_inverse_fourier_tfm_slow(fourier_image:np.ndarray) -> np.ndarray:\n",
    "    N,M = fourier_image.shape\n",
    "    output = np.zeros((N,M), dtype=complex)\n",
    "    for n in range(N):\n",
    "        for m in range(M):\n",
    "            for u in range(N):\n",
    "                for v in range(M):\n",
    "                    output[n,m] += fourier_image[u,v]*np.exp(2j*np.pi*((u*n/N)+(v*m/M)))  \n",
    "    output *= 1/(N*M)\n",
    "    return output\n",
    "\n",
    "# The FFT shift reorders the 0 frequency components to the center of the matrix. \n",
    "# This just improves our ability to interpret the fourier matrix when displayed as an image\n",
    "# low frequency data is closer to the center, and high frequency data is on the edges\n",
    "# In 2D this amounts to swapping the first and third quadrants, and the second and fourth quadrants\n",
    "def fft_shift(mtx: np.ndarray) -> np.ndarray:\n",
    "    N, M = mtx.shape\n",
    "\n",
    "    # This is a more intuitive way to understand the quadrant swapping (equivalent to np.rolls below)\n",
    "    # n_mid = (N+1)//2\n",
    "    # m_mid = (M+1)//2\n",
    "    # upper_left = mtx[0:n_mid, 0:m_mid]\n",
    "    # bottom_left = mtx[n_mid:, 0:m_mid]\n",
    "    # upper_right = mtx[0:n_mid, m_mid:]\n",
    "    # bottom_right = mtx[n_mid:, m_mid:]\n",
    "    # return np.concat((np.concat((bottom_right,bottom_left),axis=1), np.concat((upper_right, upper_left),axis=1)), axis=0)\n",
    "    return np.roll(np.roll(mtx,N//2, axis=0), M//2, axis=1)\n",
    "\n",
    "# Test case for the fft shift\n",
    "matrix = np.random.randn(10,9)\n",
    "assert(np.allclose(fft_shift(matrix), np.fft.fftshift(matrix))), \"FT Shift Failed\"\n",
    "\n",
    "def inv_fft_shift(mtx: np.ndarray) -> np.ndarray:\n",
    "    N, M = mtx.shape\n",
    "    return np.roll(np.roll(mtx,-N//2, axis=0), -M//2, axis=1)\n",
    "\n",
    "# Test case for the fft shift\n",
    "matrix = np.random.randn(10,9)\n",
    "assert(np.allclose(fft_shift(matrix), np.fft.fftshift(matrix))), \"FT Shift Failed\"\n",
    "\n",
    "\n",
    "def compute_magnitude_phase(fourier_image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    shifted_fourier = fft_shift(fourier_image)\n",
    "    magnitude = np.log1p(np.abs(shifted_fourier))\n",
    "    magnitude = magnitude / magnitude.max()\n",
    "    phase = np.angle(shifted_fourier)\n",
    "    phase = (phase + np.pi) / (2*np.pi)\n",
    "    return magnitude, phase\n",
    "\n",
    "\n",
    "matrix = np.zeros((9,9))\n",
    "center_x = matrix.shape[0] // 2\n",
    "matrix[center_x-2:center_x+2,center_x] = 1\n",
    "\n",
    "fourier_matrix = compute_fourier_tfm_slow(matrix)\n",
    "mag,phase = compute_magnitude_phase(fourier_matrix)\n",
    "inverted_matrix = compute_inverse_fourier_tfm_slow(fourier_matrix)\n",
    "\n",
    "# Test case for the slow fourier computations\n",
    "assert(np.allclose(fourier_matrix, np.fft.fft2(matrix))), \"Computing the FT failed\"\n",
    "assert(np.allclose(matrix,inverted_matrix)), \"FT inversion failed\"\n",
    "\n",
    "np_mag, np_phase = compute_magnitude_phase(np.fft.fft2(matrix))\n",
    "\n",
    "display_in_grid(\n",
    "    [[matrix, mag, phase]],\n",
    "    [[\"original image\", \"Magnitude: |F|\", \"Phase: ∠F\"]]\n",
    ")\n",
    "\n",
    "display_in_grid(\n",
    "    [[mag, phase, np.real(inverted_matrix) ]],\n",
    "    [[\"Magnitude: |F|\", \"Phase: ∠F\", \"Reconstructed Image\"]]\n",
    ")\n",
    "\n",
    "pretty_print_matrix(fft_shift(fourier_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I will display the phase, magnitude of the fourier matrix (decomposed from the complex exponential) across a set of images in the test set. I would encourage you to take a closer look at the phase/magnitude matrices and try to build an intuition for how they relate to the input image.\n",
    "\n",
    "Please note for images where the magnitude/phase values are all uniform the constructed images will be black due to how the images are normalized. Also, please take a look at fft_shift() to better understand how high/low frequency data is visualized in the fourier images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "titles = []\n",
    "fft_images_dir = 'fft_images'\n",
    "\n",
    "for image_file in sorted(os.listdir(fft_images_dir)):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img = Image.open(os.path.join(fft_images_dir, image_file)).convert('L')\n",
    "        img_arr = np.array(img) / 255.0\n",
    "        \n",
    "        fft = np.fft.fft2(img_arr)\n",
    "        fft_mag, fft_phase = compute_magnitude_phase(fft)\n",
    "        fft_inv = np.real(np.fft.ifft2(fft))\n",
    "        \n",
    "        outputs.append([img_arr, fft_mag, fft_phase, fft_inv])\n",
    "        titles.append([image_file, 'magnitude', 'phase', 'reconstructed'])\n",
    "\n",
    "\n",
    "display_in_grid(outputs, titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uses for the DFT\n",
    "\n",
    "In the next section we'll go over uses for the discrete fourier transform in image analysis. The primary ones I know about are compression and image registration/alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression: Removing high frequency terms\n",
    "\n",
    "This next cell demonstrates how removing the high frequency components from the fourier matrix can be used to compress an image. As more and more of these terms are zeroed out, you will notice that the features in the image will blur, because the finer grained edges can't be represented by the lower frequency complex exponentials.\n",
    "\n",
    "One interesting thing to note is that the sin/cos images are unaffected by this form of compression. This is because they can be represented by only the lowest frequency component of the fourier matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "titles = []\n",
    "\n",
    "for image_file in sorted(os.listdir(fft_images_dir)):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg')): \n",
    "        img = Image.open(os.path.join(fft_images_dir, image_file)).convert('L')\n",
    "        img_arr = np.array(img) / 255.0\n",
    "        \n",
    "        fft = np.fft.fft2(img_arr)\n",
    "        \n",
    "        row_titles = [image_file]\n",
    "        row_imgs = [img_arr]\n",
    "        N,M = fft.shape\n",
    "        num_steps = 7\n",
    "        for i in range(num_steps):\n",
    "            reduced_fft = fft_shift(fft.copy())\n",
    "            cutoff_n = max(1,int(N * (i+1) / num_steps / 2))\n",
    "            cutoff_m = max(1,int(M * (i+1) / num_steps / 2))\n",
    "            reduced_fft[:cutoff_n, :] = 0\n",
    "            reduced_fft[-cutoff_n:, :] = 0  \n",
    "            reduced_fft[:, -cutoff_m:] = 0  \n",
    "            reduced_fft[:, :cutoff_m] = 0\n",
    "            reduced_fft = inv_fft_shift(reduced_fft)\n",
    "            row_titles.append(f\"removed {(i+1)/num_steps:.0%}\")\n",
    "            row_imgs.append(np.real(np.fft.ifft2(reduced_fft)))\n",
    "\n",
    "        outputs.append(row_imgs)\n",
    "        titles.append(row_titles)\n",
    "\n",
    "display_in_grid(outputs, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression: Zeroing out low magnitude factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "titles = []\n",
    "\n",
    "for image_file in sorted(os.listdir(fft_images_dir)):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg')): \n",
    "        img = Image.open(os.path.join(fft_images_dir, image_file)).convert('L')\n",
    "        img_arr = np.array(img) / 255.0\n",
    "\n",
    "        fft = np.fft.fft2(img_arr)\n",
    "        flat_fft = fft.flatten()\n",
    "        mag = np.abs(flat_fft)\n",
    "\n",
    "        sorted_indices = np.argsort(mag)\n",
    "\n",
    "        percentages = [0, 10, 25, 50, 75, 90,99,99.9,99.99]\n",
    "\n",
    "        row_imgs = []\n",
    "        row_titles = []\n",
    "\n",
    "        for p in percentages:\n",
    "            mask = np.ones_like(flat_fft, dtype=bool)\n",
    "            num_zero = int(len(flat_fft) * (p / 100))\n",
    "            mask[sorted_indices[:num_zero]] = False\n",
    "            masked_fft = np.where(mask, flat_fft, 0)\n",
    "            masked_img = np.fft.ifft2(masked_fft.reshape(fft.shape)).real\n",
    "\n",
    "            row_titles.append(f\"removed {p}%\")\n",
    "            row_imgs.append(masked_img)\n",
    "\n",
    "        outputs.append(row_imgs)\n",
    "        titles.append(row_titles)\n",
    "\n",
    "display_in_grid(outputs, titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression: Towards JPEG\n",
    "\n",
    "While implementing the above compression method, I learned that JPEG compression is based on similar frequency-domain principles. At a high level, JPEG divides the image into 8×8 blocks, applies a frequency transform, and then quantizes the resulting coefficients to achieve compression.\n",
    "\n",
    "JPEG specifically uses the Discrete Cosine Transform (DCT) rather than the DFT. The DCT uses only real-valued cosine basis functions, which makes it more efficient for compression and better suited to human visual perception.\n",
    "\n",
    "\n",
    "#### Simplified Method\n",
    "I will briefly describe the method I used to perform the fourier based compression below.\n",
    "\n",
    "1. **Block-wise Decomposition**: Chunk the image into 8x8 sections\n",
    "2. **Fourier Transform**: Apply the fourier transform to this chunk and perform an fft_shift() to center the high frequency domains\n",
    "3. **Quantization**: Element-wise apply the quantization matrix (see in code)\n",
    "    - low-frequency components (closer to the center of the block [4,4]) should be preserved more than high frequency components \n",
    "    - tunable scale parameter $Q[i,j] = Q[i,j]^{scale}$ controls the compression aggressiveness\n",
    "4. **Sparsification**: Set all coefficients with magnitude < 1.0 to 0 to sparsify the fourier matrix\n",
    "5. **Storage**: Convert the result to Compressed Sparse Row (CSR) format to reduce memory usage, exploiting the sparsity introduced by quantization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantization_mtx(scale: int = 1):\n",
    "    q_mtx = np.reciprocal(np.power(np.asarray(\n",
    "        [\n",
    "            [1.06, 1.06, 1.06, 1.06, 1.05, 1.06, 1.06, 1.06],\n",
    "            [1.06, 1.06, 1.06, 1.05, 1.04, 1.05, 1.06, 1.06],\n",
    "            [1.06, 1.06, 1.05, 1.04, 1.03, 1.04, 1.05, 1.06],\n",
    "            [1.06, 1.05, 1.04, 1.03, 1.02, 1.03, 1.04, 1.05],\n",
    "            [1.05, 1.04, 1.03, 1.02, 1.01, 1.02, 1.03, 1.04],\n",
    "            [1.06, 1.05, 1.04, 1.03, 1.02, 1.03, 1.04, 1.05],\n",
    "            [1.06, 1.05, 1.05, 1.04, 1.03, 1.04, 1.05, 1.06],\n",
    "            [1.06, 1.06, 1.06, 1.05, 1.04, 1.05, 1.06, 1.06],\n",
    "        ],),scale\n",
    "    ))\n",
    "    return q_mtx\n",
    "\n",
    "def matrix_to_csr(matrix: np.ndarray):\n",
    "    rows, cols = matrix.shape\n",
    "    \n",
    "    data = []  \n",
    "    indices = []  # Column indices\n",
    "    indptr = [0]  # Row pointers\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if matrix[i,j] != 0:\n",
    "                data.append(complex(matrix[i,j]))  \n",
    "                indices.append(j)\n",
    "        indptr.append(len(data))\n",
    "    \n",
    "    data = np.array(data, dtype=complex)\n",
    "    indices = np.array(indices)\n",
    "    indptr = np.array(indptr)\n",
    "    \n",
    "    return (data, indices, indptr, (rows, cols))\n",
    "\n",
    "def csr_to_matrix(data: np.ndarray, indices: np.ndarray, indptr: np.ndarray, shape: tuple):\n",
    "    rows, cols = shape\n",
    "    matrix = np.zeros((rows, cols), dtype=complex)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        row_start = indptr[i]\n",
    "        row_end = indptr[i + 1]\n",
    "        \n",
    "        row_data = data[row_start:row_end]\n",
    "        col_indices = indices[row_start:row_end]\n",
    "        \n",
    "        if len(row_data) == 0 or len(col_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        matrix[i, col_indices] = row_data        \n",
    "\n",
    "    return matrix\n",
    "\n",
    "def simplified_jpeg_compression(img_arr: np.ndarray, scale: int = 1):\n",
    "    N, M = img_arr.shape\n",
    "    q_mtx = get_quantization_mtx(scale)\n",
    "\n",
    "    compressed_img = []\n",
    "    for i in range(0,N,8):\n",
    "        for j in range(0,M,8):\n",
    "            fft = np.fft.fft2(img_arr[i:min(i+8,N), j:min(j+8,M)])\n",
    "            out = fft_shift(fft)\n",
    "            out[np.abs(out*q_mtx[0:min(i+8,N)-i, 0:min(j+8,M)-j])<1] = 0\n",
    "            out = inv_fft_shift(out)\n",
    "            compressed_img.append((i,j,matrix_to_csr(out)))\n",
    "    \n",
    "    return compressed_img\n",
    "\n",
    "def reconstruct_img_from_jpeg(compressed_img):\n",
    "    max_i = max(i for i,_,_ in compressed_img) + 8\n",
    "    max_j = max(j for _,j,_ in compressed_img) + 8\n",
    "    \n",
    "    reconstructed = np.zeros((max_i, max_j))\n",
    "    \n",
    "    for i, j, (data, indices, indptr, shape) in compressed_img:\n",
    "        block = csr_to_matrix(data, indices, indptr, shape)\n",
    "        block = np.fft.ifft2(block).real\n",
    "        reconstructed[i:i+block.shape[0], j:j+block.shape[1]] = block\n",
    "    \n",
    "    return reconstructed\n",
    "\n",
    "def calculate_compressed_img_size(compressed_img):\n",
    "    compressed_img_bytes = 0\n",
    "    for _, _, (data, indices, indptr, _) in compressed_img:\n",
    "        compressed_img_bytes += data.nbytes + indices.nbytes + indptr.nbytes\n",
    "    return compressed_img_bytes\n",
    "\n",
    "img = Image.open(os.path.join(fft_images_dir, '10_bird.jpeg')).convert('L')\n",
    "img_arr = np.array(img) / 255.0\n",
    "original_bytes = img_arr.nbytes\n",
    "\n",
    "outputs = [img_arr]\n",
    "titles = [f\"original {original_bytes / 1024:.2f}KB\"]\n",
    "\n",
    "for scale in np.linspace(0,300,5):\n",
    "    compressed_img = simplified_jpeg_compression(img_arr,scale)\n",
    "    compressed_img_bytes = calculate_compressed_img_size(compressed_img)\n",
    "\n",
    "    original_kb = original_bytes / 1024\n",
    "    compressed_kb = compressed_img_bytes / 1024\n",
    "    compression_ratio = original_bytes / compressed_img_bytes\n",
    "    \n",
    "    outputs.append(reconstruct_img_from_jpeg(compressed_img))\n",
    "    titles.append(f\"{compressed_img_bytes / 1024:.2f} KB\\nscale={int(scale)}\\nCompression ratio: {compression_ratio:.2f}x\")\n",
    "\n",
    "display_in_grid([outputs],[titles])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This compression method has limitations - especially on smaller images. I intentionally skipped certain boundary cases for simplicity, so some outputs may contain black padding at the edges. Additionally, the quantization matrix I used is a rough heuristic and not tuned for general-purpose compression. As a result, the algorithm performs poorly on some simple images. (In practice, effective quantization matrices are often highly optimized—and sometimes even patented.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(fft_images_dir) if f.endswith(('.jpeg', '.png'))]\n",
    "\n",
    "all_outputs = []\n",
    "all_titles = []\n",
    "\n",
    "for image_file in sorted(image_files):\n",
    "    img = Image.open(os.path.join(fft_images_dir, image_file)).convert('L')\n",
    "    img_arr = np.array(img) / 255.0\n",
    "    original_bytes = img_arr.nbytes\n",
    "\n",
    "    outputs = [img_arr]\n",
    "    titles = [f\"{image_file}\\noriginal {original_bytes / 1024:.2f}KB\"]\n",
    "\n",
    "    for scale in np.linspace(0,300,5):\n",
    "        compressed_img = simplified_jpeg_compression(img_arr,scale)\n",
    "        # Calculate and display memory usage of compressed_img\n",
    "        compressed_img_bytes = calculate_compressed_img_size(compressed_img)\n",
    "        original_kb = original_bytes / 1024\n",
    "        compressed_kb = compressed_img_bytes / 1024\n",
    "        compression_ratio = original_bytes / compressed_img_bytes\n",
    "\n",
    "        outputs.append(reconstruct_img_from_jpeg(compressed_img))\n",
    "        titles.append(f\"{compressed_img_bytes / 1024:.2f} KB\\nscale={int(scale)}\\nCompression ratio: {compression_ratio:.2f}x\")\n",
    "    \n",
    "    all_outputs.append(outputs)\n",
    "    all_titles.append(titles)\n",
    "\n",
    "display_in_grid(all_outputs, all_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Matching\n",
    "\n",
    "Template matching is often computationally expensive because we need to compute the cross-correlation between a template $T$ and an image $I$ at every possible spatial offset - essentially sliding the template over the image and measuring the similarity at each location. This produces an output map $C$ where high values indicate strong matches.\n",
    "\n",
    "Fortunately, due to the Convolution Theorem, we can compute this more efficiently in the frequency domain. Cross-correlation can be computed by applying the FFT to both $I$ and $T$, multiplying $F(I)$ with the complex conjugate of $F(T)$, and applying the inverse FFT to get back to the spatial domain. The result is a correlation map where high values correspond to locations where the template matches the image.\n",
    "\n",
    "**Convolution Theorem**: $f(t)\\circledast g(t) = F^{-1}(F(f(t))\\cdot\\overline{F(g(t))})$\n",
    "\n",
    "\n",
    "**Cross Correlation**: $C = F^{-1}(F(I) \\cdot \\overline{F(T)})$\n",
    "\n",
    "\n",
    "Note: for visualization purposes, I perform non maximal suppression on the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def match_via_convolution(image: np.ndarray, template: np.ndarray) -> np.ndarray:\n",
    "    N,M = image.shape\n",
    "    Nt, Mt = template.shape\n",
    "    template = template - np.mean(template)\n",
    "    template = template / np.max(np.abs(template))\n",
    "    response = np.zeros_like(image)\n",
    "    for i in range(0, N-Nt+1):\n",
    "        for j in range(0,M-Mt+1):\n",
    "            patch = image[i:i+Nt, j:j+Mt]\n",
    "            patch = patch - np.mean(patch)\n",
    "            patch = patch / np.max(np.abs(patch))\n",
    "            response[i,j] = np.sum(patch*template)\n",
    "    \n",
    "    response = response - np.mean(response)\n",
    "    response = response / np.max(np.abs(response))\n",
    "    return response\n",
    "\n",
    "def match_via_fft(image: np.ndarray, template: np.ndarray) -> np.ndarray:\n",
    "    N, M = image.shape\n",
    "    Nt, Mt = template.shape\n",
    "    assert (N>=Nt and M>=Mt), \"template should be smaller than image\"\n",
    "    template = template - np.mean(template)\n",
    "    template = template / np.max(np.abs(template))\n",
    "    padded_template = np.zeros_like(image)\n",
    "    padded_template[:Nt, :Mt] = template\n",
    "\n",
    "    Ft = np.fft.fft2(padded_template)\n",
    "    Fi = np.fft.fft2(image)\n",
    "    corr = np.real(np.fft.ifft2(Fi * np.conj(Ft)))\n",
    "    corr = corr - np.mean(corr)\n",
    "    corr = corr / np.max(np.abs(corr))\n",
    "    return corr\n",
    "\n",
    "def compute_iou(loc1, loc2, Nt, Mt):\n",
    "        x1, y1 = loc1\n",
    "        x2, y2 = loc2\n",
    "        x_left = max(x1, x2)\n",
    "        y_top = max(y1, y2)\n",
    "        x_right = min(x1 + Nt, x2 + Nt)\n",
    "        y_bottom = min(y1 + Mt, y2 + Mt)\n",
    "        if x_right <= x_left or y_bottom <= y_top:\n",
    "            return 0.0\n",
    "        intersection = (x_right - x_left) * (y_bottom - y_top)\n",
    "        union = 2*Nt*Mt - intersection\n",
    "        return intersection / union\n",
    "\n",
    "def perform_non_maximal_suppression(match: np.ndarray, loc: np.ndarray, Nt: int, Mt: int, iou_threshold: float):\n",
    "    n = loc.shape[0]\n",
    "    if n <= 1:\n",
    "        return list(loc)\n",
    "    \n",
    "    scores = match[loc[:, 0], loc[:, 1]]\n",
    "    sorted_indices = np.argsort(-scores)\n",
    "    loc = loc[sorted_indices]\n",
    "\n",
    "    kept_locations = []\n",
    "    for i in range(len(loc)):\n",
    "        should_keep = True\n",
    "        current_loc = (loc[i,0], loc[i,1])\n",
    "        for kept_loc in kept_locations:\n",
    "            iou = compute_iou(current_loc, kept_loc, Nt, Mt)\n",
    "            if iou > iou_threshold:\n",
    "                should_keep = False\n",
    "                break\n",
    "        if should_keep:\n",
    "            kept_locations.append(current_loc)\n",
    "    \n",
    "    return np.asarray(kept_locations)\n",
    "\n",
    "def threshold_and_display_boxes(image: np.ndarray, match: np.ndarray, Nt: int, Mt: int, threshold: float) -> np.ndarray:\n",
    "    N, M = image.shape\n",
    "    out = image.copy()\n",
    "    locations = np.argwhere(match > threshold)\n",
    "    locations = perform_non_maximal_suppression(match, locations, Nt, Mt, .3)\n",
    "    \n",
    "    def draw_rectangle(img: np.ndarray, x: int, y:int, Nt: int, Mt: int):\n",
    "        img[x:min(x+Nt, N-1),y] = 0.0\n",
    "        img[x:min(x+Nt, N-1),min(M-1,y+Mt)] = 0.0\n",
    "        img[x,y:min(M-1,y+Mt)] = 0.0\n",
    "        img[min(x+Nt, N-1),y:min(M-1,y+Mt)] = 0.0\n",
    "        return img\n",
    "    \n",
    "    for x,y in locations:\n",
    "        out = draw_rectangle(out, x,y,Nt,Mt)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "img = Image.open(os.path.join('template_matching', 'cards.jpg')).convert('L')\n",
    "template = Image.open(os.path.join('template_matching', 'template.jpg')).convert('L')\n",
    "img_arr = np.array(img) / 255.0\n",
    "template_arr = np.array(template) / 255.0\n",
    "start_time = time.time()\n",
    "conv_match = match_via_convolution(img_arr, template_arr)\n",
    "conv_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "fft_match = match_via_fft(img_arr, template_arr)\n",
    "fft_time = time.time() - start_time\n",
    "\n",
    "display_in_grid(\n",
    "    [[img_arr, template_arr],[ conv_match, fft_match]],\n",
    "    [[\"img\", \"template\"],[f\"conv_match ({conv_time:.2f}s)\", f\"fft_match ({fft_time:.2f}s)\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "titles = []\n",
    "for matches, name in zip([conv_match, fft_match],[\"conv\", \"fft\"]):\n",
    "    row_outputs = []\n",
    "    row_titles = []\n",
    "    for threshold in [.99,.9,.7,.4,.2]:\n",
    "        row_outputs.append(threshold_and_display_boxes(img_arr, matches, template_arr.shape[0], template_arr.shape[1], threshold))\n",
    "        row_titles.append(f\"{name} threshold={threshold}\")\n",
    "    outputs.append(row_outputs)\n",
    "    titles.append(row_titles)\n",
    "\n",
    "display_in_grid(outputs,titles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
